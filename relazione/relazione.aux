\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wang2018gene}
\citation{Dua:2019}
\citation{weinstein2013cancer}
\@writefile{toc}{\contentsline {section}{\numberline {1}Dataset description}{3}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Dataset Manipulation}{3}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Preliminary manipulation}{3}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Label handling}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Normalization}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Train and Test Set}{4}{subsection.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Class Weighting}{4}{subsection.2.5}\protected@file@percent }
\citation{geron2017hands}
\citation{bishop2006pattern}
\citation{hertz1991introduction}
\@writefile{toc}{\contentsline {section}{\numberline {3}Models}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Decision Tree Classifier and Random Forests}{5}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Shape of a tree classifier with tuned hyperparameters}}{6}{figure.1}\protected@file@percent }
\newlabel{fig1}{{1}{6}{Shape of a tree classifier with tuned hyperparameters}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Support Vector Machines (SVM)}{6}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Deep Learning}{7}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Keras}{7}{subsubsection.3.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}PyTorch}{8}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Neural network architecture, losses and optimizers}{8}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Architecture}{8}{subsubsection.3.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.2}Losses}{9}{subsubsection.3.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.3}Optimizers}{9}{subsubsection.3.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Parameter optimization and Validation}{12}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cross-Validation}{12}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Grid Search and Random Search}{12}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Architecture settings}{13}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Decision Tree}{13}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Random Forest}{13}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Support Vector Machine}{13}{subsubsection.4.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Models Evaluation}{14}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Feature Selection and Dimensionality Reduction}{14}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces On the left: permutation importance for the parameter tuned tree; it clearly shows that only a low number of genes is correlated with the prediction. On the right: a visual description using Shape library of how these features influence the data prediction.}}{15}{figure.2}\protected@file@percent }
\newlabel{fig_perm}{{2}{15}{On the left: permutation importance for the parameter tuned tree; it clearly shows that only a low number of genes is correlated with the prediction. On the right: a visual description using Shape library of how these features influence the data prediction}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Confusion matrix and evaluation metrics for the tree classifier trained with only relevant genes.}}{15}{figure.3}\protected@file@percent }
\newlabel{fig_perm_m}{{3}{15}{Confusion matrix and evaluation metrics for the tree classifier trained with only relevant genes}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Metrics}{16}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}Models results}{16}{subsubsection.5.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces On the left the confusion matrix for the Decision Tree; on the right the Random Forest one.}}{17}{figure.4}\protected@file@percent }
\newlabel{fig_treeandforest}{{4}{17}{On the left the confusion matrix for the Decision Tree; on the right the Random Forest one}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Confusion matrix for the optimal Support Vector Machine.}}{17}{figure.5}\protected@file@percent }
\newlabel{fig_svm}{{5}{17}{Confusion matrix for the optimal Support Vector Machine}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces On the left the confusion matrix for the Keras Deep Neural Network with One-Hot encoded labels; on the left the Pytorch one (results for Label and One-Hot Encoding are the same).}}{18}{figure.6}\protected@file@percent }
\newlabel{fig_deep}{{6}{18}{On the left the confusion matrix for the Keras Deep Neural Network with One-Hot encoded labels; on the left the Pytorch one (results for Label and One-Hot Encoding are the same)}{figure.6}{}}
\bibdata{Bibliography}
\bibcite{wang2018gene}{1}
\bibcite{Dua:2019}{2}
\bibcite{weinstein2013cancer}{3}
\bibcite{geron2017hands}{4}
\bibcite{bishop2006pattern}{5}
\bibcite{hertz1991introduction}{6}
\bibstyle{unsrt}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Outlook}{19}{section.6}\protected@file@percent }
